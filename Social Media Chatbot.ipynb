{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Zelf een social media chatbot maken<h1/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vandaag gaan jullie kennis maken met een chatbot die je zelf gaat coderen. Deze chatbot is gebouwd met code in Python en kan veel dingen doen: \n",
    "* luisteren, praten en op jouw stem reageren\n",
    "* gezichten herkennen (zoals in Facebook!)\n",
    "* gezichten maskeren met verschillende funfilters (zoals in Snapchat!).\n",
    "\n",
    "<img src=\"chat-icon.png\" height=\"30%\" width=\"30%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Introductie</h2>\n",
    "Tijdens het komende uur zullen jullie de chatrobot steeds slimmer maken. We gaan de Chatbot bouwen in drie stappen:\n",
    "1. We leren de Chatbot praten. We gaan haar een “mond” geven en jou leren hoe je de Chatbot instrueert wat zij moet zeggen.\n",
    "2. We leren de Chatbot luisteren. We geven haar “oren” en zorgen dat zij wat jij zegt kan vertalen naar tekst (van geluid, naar geschreven tekst)\n",
    "3. We gaan de Chatbot leren reageren op wat jij zegt. We leren haar vragen van jou te beantwoorden. \n",
    "\n",
    "Volg de instructies stap voor stap en let goed op dat je de code goed overneemt: computers zijn heel precies en een klein foutje kan ervoor zorgen dat je code niet werkt. \n",
    "\n",
    "Loop je vast? \n",
    "Kijk dan goed of je de code goed hebt overgenomen. Let ook op dat witruimte aan het begin van de regel (waar de tekst inspringt) voor Python belangrijk is. Zorg dat je daar met de Tab-toets of spatiebalk ook witruimte maakt. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Opdracht 1 – Opstarten & Praten</h2>\n",
    "Ok, we gaan beginnen! Om de robot te leren praten gebruiken we de code uit cell 1 en cell 2.\n",
    "Wat de code in cell 1 doet is het volgende: deze regels importeren code die anderen geschreven hebben die wij weer kunnen gebruiken. Zo hoeven we bijvoorbeeld niet na te denken over hoe de luidspreker van je laptop werkt. Iemand anders heeft dat al bedacht en code voor geschreven. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 1.9.6\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "from gtts import gTTS\n",
    "#from playsound import playsound\n",
    "import speech_recognition as sr\n",
    "import pygame\n",
    "import io\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De regel in de volgende cell dat met \"def\" begint is de start van een functie. \n",
    "Een functie is een stukje code die je zelf vaker wilt gebruiken en zo makkelijker kunt aanroepen. \n",
    "\n",
    "In plaats van elke keer alles te schrijven hoef je nu als je bijvoorbeeld \"Hoi, hoe gaat het\" wilt zeggen alleen maar \"say(\"Hoi, hoe gaat het\")\" te schrijven. \n",
    "De regels daaronder doen het echte werk: de tekst-to-speech functie van Google wordt aangeroepen en er komt een geluidsbestand terug. Die speelt jouw computer af en voila: je computer kan praten!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def say(text, language='nl'):\n",
    "\ttts = gTTS(text, lang=language)\n",
    "\tprint(\"Bea zegt: \"+text)\n",
    "\tfp = io.BytesIO()\n",
    "\ttts.write_to_fp(fp)\n",
    "\tfp.seek(0)\n",
    "\tpygame.mixer.init()\n",
    "\tpygame.mixer.music.load(fp)\n",
    "\tpygame.mixer.music.play()\n",
    "\twhile pygame.mixer.music.get_busy():\n",
    "\t\tpygame.time.Clock().tick(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Toen je de code hierboven uitvoert, zal je merken dat er nog niks gebeurt. Hoe kan dit? \n",
    "\n",
    "Dat komt omdat je wel de functie \"say(..)\" hebt gemaakt, maar deze nog niet aanroept. Aanroepen gaat heel makkelijk. Gebruik de code uit de cell hieronder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bea zegt: Hallo, mijn naam is Bea de Chatbot.\n"
     ]
    }
   ],
   "source": [
    "say(\"Hallo, mijn naam is Bea de Chatbot.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool he? Kun je de code aanpassen en de Chatbot andere dingen laten zeggen? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# laat Bea iets anders zeggen\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bea kent veel talen! Ze kan bijvoorbeeld ook in het Fraans praten:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "say(\"Salut, je suis contente parce que je parle beaucoup de langues.\", language=\"fr\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spreek je nog een andere taal? Dan probeer om Bea iets in die taal te zeggen! Dit zijn de talen die je kan uitproberen:\n",
    "    1. 'en' for English\n",
    "    2. 'fr' for French\n",
    "    3. 'de' for German\n",
    "    4. 'it' for Italian\n",
    "    5. 'es' for Spanish\n",
    "    6. 'pt' for Portuguese\n",
    "    7. 'ja' for Japanese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# laat Bea in een andere taal praten \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Opdracht 2 – Luisteren</h2>\n",
    "Dat was praten. Nu gaan we zorgen dat de Chatbot kan luisteren! \n",
    "De code uit de volgende cell creëert een functie om de chatbot leren te luisteren.\n",
    "Met de functie \"listen(..)\" (weer een functie!) kunnen we luisteren naar het geluid via de microfoon en dat in geschreven tekst omzetten. \n",
    "\n",
    "Deze code doet het volgende. We starten de spraakherkenner met “r = sr.Recognizer()”. Dan zeggen we bij de regel die begint met “with” dat de spraakherkenner naar de audio uit de microfoon moet luisteren tot zij geluid heeft opgevangen. \n",
    "\n",
    "De regel die begint met “Try” vertelt de computer dat zij de code op de regel erop moet proberen uit te voeren. \n",
    "Die regel stuurt het geluid naar de servers van Google en krijgt (als alles goed gaat!) een geschreven tekst terug. Mocht dat misgaan dan zijn de regels erop (die beginnen met “Except”) bedoeld om te zeggen dat het misging. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def listen():\n",
    "\tr = sr.Recognizer()\n",
    "\twith sr.Microphone() as source:\n",
    "\t\t#audio = r.adjust_for_ambient_noise(source)\n",
    "\t\tprint(\"Bea is aan het luisteren...\")\n",
    "\t\taudio = r.listen(source)\n",
    "\ttry:\n",
    "\t\taudio = r.recognize_google(audio, language=\"nl\")\n",
    "\t\tprint(\"Je hebt gezegd: \"+audio)\n",
    "\t\treturn audio.lower()\n",
    "\texcept sr.UnknownValueError:\n",
    "\t\tprint(\"Ik kon je niet verstaan\")\n",
    "\t\treturn None\n",
    "\texcept sr.RequestError as e:\n",
    "\t\tprint(\"Oeps, er is een fout; {0}\".format(e))\n",
    "\t\treturn None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nu wil je vast wel eens zien hoe deze functie werkt? Gebruik daarvoor de code uit de volgende cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "say(\"Wat is jouw naam?\")\n",
    "name = listen()\n",
    "if name is not None:\n",
    "    say(\"Hallo \" + name + \", Leuk je te ontmoeten!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kijk naar de code hieronder. Wat kan je zeggen om Bea 'tot ziens' laten zeggen? Laten we maar proberen!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Opdracht 3 – Vragen beantwoorden</h2>\n",
    "Nu de robot kan praten en kan luisteren willen we dat de Chatbot gaat reageren op jouw vragen. \n",
    "We beginnen met een simpele vraag en maken het dan iets moeilijker. \n",
    "Ben je er klaar voor? \n",
    "\n",
    "Als je de code hieronder nu uitvoert gebeurt er het volgende. De While loop waarmee de code begint zorgt ervoor dat de code eronder continue herhaalt wordt. Je programma houdt dus nooit meer op (tenzij jij het zegt te stoppen natuurlijk). Dan wordt er een Dictionary aangemaakt. We slaan hier een combinatie van sleutelwoorden en antwoorden op. Dit wordt belangrijk voor de Chatbot: zij kijkt of zij deze sleutelwoorden in jouw vraagt ziet en reageert dan met het antwoord. Met \"question = listen()\" luistert de Chatbot naar jouw vraag. Als de vraag niet None is heb jij iets gezegd. Zij kijkt dan of een van zijn sleutelwoorden (\"keyword\") in jouw vraag voorkwam en als dat zo is geeft zij het bijpassende antwoord. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Add examples related to social media\n",
    "keyword_and_answers = {\n",
    "    \"wat kun je\": \"Ik kan veel. Maar alleen wat jij mij leert.\",\n",
    "    \"hoe heet je\": \"Mijn naam is Bea de Chatbot\",\n",
    "    \"spruitjes\": \"Spruitjes vind ik heel vies!\",\n",
    "    \"gebruik je facebook\": \"ja dat vind ik leuk!\"\n",
    "}\n",
    "stop = False\n",
    "while not stop:\n",
    "\tsay(\"Wat kan ik voor jou doen?\")\n",
    "\tquestion = listen()\n",
    "\tif question is not None:\n",
    "\t\tprint(\"I am trying to answer\")\n",
    "\t\tstop = True\n",
    "\t\tfor keyword, answer in keyword_and_answers.items():\n",
    "\t\t\tif keyword in question:\n",
    "\t\t\t\tsay(answer)\n",
    "\t\t\t\tstop = False\n",
    "\t\tif stop:\n",
    "\t\t\tsay(\"Dankjewel. Tot ziens!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Opdracht 4 – Gezichten herkennen</h2>\n",
    "Facebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_faces_from_image(image_path):\n",
    "    # load image\n",
    "    img = cv2.imread(image_path)\n",
    "\n",
    "    # convert to grayscale as opencv face detector expects gray images\n",
    "    gray_image = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # load pre-trained face classifier \n",
    "    face_classifier = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "    faces_rects = face_classifier.detectMultiScale(gray_image, scaleFactor=1.3, minNeighbors=5)\n",
    "    print('Faces found: ', len(faces_rects))\n",
    "\n",
    "    for (x, y, w, h) in faces_rects:\n",
    "        cv2.rectangle(img, (x, y), (x+w, y+h), color=(255, 205, 50), thickness=15)\n",
    "\n",
    "    # convert to RGB and display image\n",
    "    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the image to be tested\n",
    "test_image = cv2.imread('rosa.siervo.jpg')\n",
    "\n",
    "# Displaying the image\n",
    "plt.imshow(cv2.cvtColor(test_image, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = \"rosa.siervo.jpg\"\n",
    "detect_faces_from_image(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_faces_from_camera():\n",
    "    # get stream pointer to the default camera\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    # load pre-trained face classifier \n",
    "    face_classifier = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "    \n",
    "    # loop over frames from the video file stream   \n",
    "    while True:\n",
    "        # grab the current frame from the video stream and its return code (which can be ignored)\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        # convert to grayscale as opencv face detector expects gray images (because it was trained on gray images)\n",
    "        gray_image = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # detect faces in the frame\n",
    "        faces_rects = face_classifier.detectMultiScale(gray_image, scaleFactor=1.3, minNeighbors=5)\n",
    "\n",
    "        # add bounding boxes around detected faces\n",
    "        for (x, y, w, h) in faces_rects:\n",
    "                cv2.rectangle(frame, (x, y), (x+w, y+h), color=(255, 205, 50), thickness=2)\n",
    "\n",
    "        # display the resulting frame\n",
    "        cv2.imshow('Video', frame)\n",
    "\n",
    "        # if the ‘q’ key is pressed or the window is manually closed, exit the while loop\n",
    "        if ((cv2.waitKey(1) & 0xFF == ord('q')) or (cv2.getWindowProperty('Video',cv2.WND_PROP_VISIBLE) < 1)):\n",
    "            break\n",
    "    \n",
    "    # close the window \n",
    "    cap.release()\n",
    "    # de-allocate any associated memory usage \n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detect_faces_from_camera()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Opdracht 4 – Gezichten maskeren met Funfilters</h2>\n",
    "Snapchat."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Heel goed gedaan! Nadat Bea het gezicht kan vinden, wil ze een hoed opzetten! Op deze manier kan ze hetzelfde als in Snapchat! Kan je haar helpen?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_faces_from_image_with_dog(image_path, mask_path):\n",
    "    # load image\n",
    "    img = cv2.imread(image_path)\n",
    "        \n",
    "    # convert to grayscale as opencv face detector expects gray images\n",
    "    gray_image = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # load pre-trained face classifier \n",
    "    face_classifier = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "    faces_rects = face_classifier.detectMultiScale(gray_image, scaleFactor=1.3, minNeighbors=5)\n",
    "    print('Faces found: ', len(faces_rects))\n",
    "    \n",
    "    # load the mask\n",
    "    mask = cv2.imread(mask_path)\n",
    "    for (x, y, w, h) in faces_rects:\n",
    "        # draw bounding box around the detected face\n",
    "        #cv2.rectangle(img, (x, y), (x+w, y+h), color=(255, 205, 50), thickness=2)\n",
    "        # crop a frame slightly larger than the face\n",
    "        if int(y - 0.20*h) > 0:\n",
    "            y = int(y - 0.20*h)\n",
    "        h = int(0.80*h) \n",
    "        \n",
    "        # resize the mask to fit on face\n",
    "        mask = cv2.resize(mask, (w, h))\n",
    "        \n",
    "        # compute pixels in the mask that are not white or near-white\n",
    "        non_white_pixels = (mask < 250).all(axis=2)\n",
    "        # put the mask on top of the face\n",
    "        img[y: y+h, x:x+w][non_white_pixels] = mask[non_white_pixels]\n",
    "\n",
    "    # convert to RGB and display image\n",
    "    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Current options: 'dalmatian_mask.png' 'sheepdog_mask.png', 'dog_mask.png'\n",
    "mask_faces_from_image_with_dog('kids.png', 'dalmatian_mask.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_faces_from_camera_with_dog(mask_path):\n",
    "    # get stream pointer to the default camera\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    # load pre-trained face classifier \n",
    "    face_classifier = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "    \n",
    "    # load the mask\n",
    "    mask = cv2.imread(mask_path)\n",
    "    \n",
    "    # loop over frames from the video file stream   \n",
    "    while True:\n",
    "        # grab the current frame from the video stream and its return code (which can be ignored)\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        # convert to grayscale as opencv face detector expects gray images (because it was trained on gray images)\n",
    "        gray_image = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # detect faces in the frame\n",
    "        faces_rects = face_classifier.detectMultiScale(gray_image, scaleFactor=1.3, minNeighbors=5)\n",
    "\n",
    "        # add bounding boxes around detected faces\n",
    "        for (x, y, w, h) in faces_rects:\n",
    "            #cv2.rectangle(frame, (x, y), (x+w, y+h), color=(255, 205, 50), thickness=2)\n",
    "            # crop a frame slightly larger than the face\n",
    "            if int(y - 0.20*h) > 0:\n",
    "                y = int(y - 0.20*h)\n",
    "            h = int(0.80*h) \n",
    "\n",
    "            # resize the mask to fit on face\n",
    "            resized_mask = cv2.resize(mask, (w, h))\n",
    "\n",
    "            # compute pixels in the mask that are not white or near-white\n",
    "            non_white_pixels = (resized_mask < 250).all(axis=2)\n",
    "            # put the mask on top of the face\n",
    "            frame[y: y+h, x:x+w][non_white_pixels] = resized_mask[non_white_pixels]\n",
    "\n",
    "            # display the resulting frame\n",
    "            cv2.imshow('Video', frame)\n",
    "\n",
    "        # if the ‘q’ key is pressed or the window is manually closed, exit the while loop\n",
    "        if ((cv2.waitKey(1) & 0xFF == ord('q')) or (cv2.getWindowProperty('Video',cv2.WND_PROP_VISIBLE) < 1)):\n",
    "            break\n",
    "    \n",
    "    # close the window \n",
    "    cap.release()\n",
    "    # de-allocate any associated memory usage \n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_faces_from_camera_with_dog('dog_mask.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
